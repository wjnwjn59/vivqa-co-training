# VLM for VQG model configuration
name: "/mnt/dataset1/pretrained_fm/unsloth_Qwen2-VL-7B-Instruct"
tokenizer: 
  add_special_tokens: true
quantization:
  is_quantize: false
  quantization_config:
    load_in_4bit: false
    load_in_8bit: false
dtype: bfloat16
generation_config:
  random_state: 59
  do_sample: false
  batch_size: 1
  max_new_tokens: 512
  temperature: 0.0001
  top_p: 1.0
  top_k: 50